{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lecture 15: APIs\n",
    "\n",
    "April 17, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Accessing data through APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APIs\n",
    "\n",
    "- An API (Application Programming Interface) is an interface that sits on top of a computer-based system and simplifies certain tasks, such as extracting subsets of data from a large repository or database.\n",
    "- Real-time server-to-browser communication.\n",
    "- An API is code that allows software programs to communicate.\n",
    "- Web APIs allow you to access data available via an internet web interface.\n",
    "- Often you can access data from web APIs using a URL that contains sets of parameters that specifies the type and particular subset of data that you are interested in.\n",
    "- Web APIs are a way to strip away all the extraneous visual interface that you don't care about and get the data that you want."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### JSON files\n",
    "\n",
    "- Data from APIs are often JSONs (JavaScript Object Notation)\n",
    "- Structured Machine-readable files: Files that can be stored in a text format but are hierarchical and structured in some way that optimizes machine readability. JSON files are an example of structured machine-readable files.\n",
    "- They are stored in human-readable text.\n",
    "- They are 'lightweight' for storing and transferring data. This makes it very easy to work with quickly and productively. The specification is designed to minimize the number of requests and the amount of data that needs sending between client and server.\n",
    "- Python is particularly good at reading in JSON files.\n",
    "- It usually makes sense to load these in to Python as dictionaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why do we use APIs?\n",
    "\n",
    "Among other things, APIs allow us to:\n",
    "- Get information that would be time-consuming to get otherwise.\n",
    "- Get information that you can't get otherwise.\n",
    "- Automate analytical workflows that require continuously updated data.\n",
    "- Access data using a more direct interface.\n",
    "- There are many different types of web APIs. One of the most common types is a REST, or RESTful, API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A RESTful API is a web API that uses URL arguments to specify what information you want returned through the API."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using APIs\n",
    "\n",
    "- API is actually a very simple tool that allows anyone to access information from a given website. You might require the use of certain headers but some APIs require just the URL.\n",
    "- Data REQUEST: You try to access a URL in your browser.\n",
    "- Data processing: A web server somewhere that uses URL to query a specified dataset.\n",
    "- Data RESPONSE: That web server then sends you back some content."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python libraries for accessing APIs\n",
    "\n",
    "- As part of accessing the API content and getting the data into a .CSV file, we'll have to import a number of Python Libraries.\n",
    "- `requests` library helps us get the content from the API by using the `get()` method. The `json()` method converts the API response to JSON format for easy handling.\n",
    "- `json` library is needed so that we can work with the JSON content we get from the API.\n",
    "- `pandas` library helps to create a DataFrame which we can format with proper headings and indexing, and then analyze."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Open Notify API example\n",
    "\n",
    "- Now collect data from the Open Notify API. This example follows https://www.dataquest.io/blog/python-api-tutorial/.\n",
    "- The Open Notify API gives access to data about the international space station. It's a great API for learning because it has a very simple design, and doesn't require authentication.\n",
    "- The first endpoint we'll use is http://api.open-notify.org/astros.json, which returns data about astronauts currently in space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "\n",
    "response = requests.get(\"http://api.open-notify.org/astros.json\")\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We received a '200' code which tells us our request was successful. The documentation tells us that the API response we'll get is in JSON format. Next, let's use the response.json() method to see the data we received back from the API:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert this to a pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iss_df = pd.DataFrame(response.json())\n",
    "print(iss_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not how we would like our data frame to look. The message and number columns are unnecessary. Remove them and convert the people column to a data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.json()['people'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iss_df = pd.DataFrame(response.json()['people'])\n",
    "print(iss_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Colorado Population Projections Example\n",
    "\n",
    "See what the dataset looks like at the bottom of this page: https://data.colorado.gov/Demographics/Population-Projections-in-Colorado/q5vp-adf3\n",
    "\n",
    "At the top of the page, you will notice an API button. If you click on that, it gives you the URL for accessing the API: https://data.colorado.gov/resource/q5vp-adf3.json\n",
    "\n",
    "We will use this URL in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.colorado.gov/resource/q5vp-adf3.json\"\n",
    "requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the code\n",
    "\n",
    "- `requests.get(url).json()` outputs the data at the URL as a JSON to the console.\n",
    "- We will save this as JSON_data: `JSON_data = requests.get(url).json()`\n",
    "- Use `json.dumps(JSON_data)` to print the data to the console without indentation.\n",
    "- Notice that the data looks like a Python dictionary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_data = requests.get(url).json()\n",
    "my_data = json.dumps(JSON_data)\n",
    "# print(my_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall that `JSON_data = requests.get(url).json()`\n",
    "- To convert the JSON_data to a pandas DataFrame, simply use `pd.DataFrame`: `pop_df = pd.DataFrame(JSON_data)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = pd.DataFrame(JSON_data)\n",
    "print(pop_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 RESTful APIs\n",
    "\n",
    "- There are ways of doing more complex extractions using the API string. I will show these in the next few slides. These are RESTful APIs.\n",
    "- REST (REpresentational State Transfer) is an architectural style, and an approach to communications that is often used in the development of Web services. The use of REST is often preferred over the more heavyweight SOAP (Simple Object Access Protocol) style because REST does not leverage as much bandwidth, which makes it a better fit for use over the Internet\n",
    "- However, unless there is a huge amount of data, we are more confident doing this filtering in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Using REST API for Colorado Population Projections Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://data.colorado.gov/resource/tv8u-hswn.json?county=Boulder&$where=age between 20 and 40 and year between 2016 and 2025&$select=year,age,femalepopulation'\n",
    "\n",
    "JSON_data = requests.get(url).json()\n",
    "# print(JSON_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "pop_df_filter = pd.DataFrame(JSON_data)\n",
    "print(pop_df_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking down the API string\n",
    "\n",
    "Notice that the colorado.data.gov API URL in the cell above starts with data.colorado.gov but then has various parameters attached to the end of the URL that specify the particular type of information that you are looking for.\n",
    "\n",
    "The parameters in the url are:\n",
    "- The Data set itself: `/tv8u-hswn.json`\n",
    "- AGE: `where=age between 20 and 40`\n",
    "- YEAR: `year between 2016 and 2025`\n",
    "- COUNTY: `county=Boulder`\n",
    "- Columns to get: `select=year,age,femalepopulation`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 Exercise\n",
    "\n",
    "Do your own filtering of data from the Colorado population projection data using an API string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 Newspaper search example\n",
    "\n",
    "- We will now look at the Chronicling America API. Details on how to use it are at the following link: https://chroniclingamerica.loc.gov/about/api/\n",
    "- The base URL for the API is: https://chroniclingamerica.loc.gov/\n",
    "- The Chronicling America API allows access to metadata and text for millions of scanned newspaper pages. In addition, unlike many other APIs, it also does not require an authentication process, allowing us to immediately explore the available data without signing up for an account.\n",
    "- In our example, we will try to find data on when Castleblayney was mentioned in an American paper.\n",
    "- From the about API page, we see that the URL for creating a request to the API is: http://chroniclingamerica.loc.gov/search/pages/results/\n",
    "- We see that this contains all results.\n",
    "- We want to search for Castleblayney in JSON format. To do this add `?andtext=castleblayney&format=json`: https://chroniclingamerica.loc.gov/search/pages/results/?andtext=castleblayney&format=json\n",
    "- If we request this URL, convert it to a JSON file, and try to convert it to a DataFrame, it is not in the format we would like.\n",
    "- Notice that the items column appears to contain the dictionary we would like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://chroniclingamerica.loc.gov/search/pages/results/?andtext=castleblayney&format=json\"\n",
    "# JSONContent = requests.get(url, headers={'content-type':'application/json'}).json()\n",
    "\n",
    "JSONContent = requests.get(url).json()\n",
    "\n",
    "blayney_df = pd.DataFrame(JSONContent)\n",
    "print(blayney_df)\n",
    "print(blayney_df.iloc[0:2,0:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we apply `pd.DataFrame` to `JSONContent['items']`, we get the dataset we would like.\n",
    "- There are some missing values and strangely formatted columns. These would have to be tidied up.\n",
    "- This only gives the data for the first 20 results. How do you think we will access the data for the other results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blayney_df = pd.DataFrame(JSONContent['items'])\n",
    "# blayney_df\n",
    "print(blayney_df.head())\n",
    "# print(blayney_df.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use the page argument to see results other than the first 20: https://chroniclingamerica.loc.gov/search/pages/results/?andtext=castleblayney&format=json&page=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://chroniclingamerica.loc.gov/search/pages/results/?andtext=castleblayney&format=json&page=2\"\n",
    "JSONContent2 = requests.get(url).json()\n",
    "\n",
    "blayney_df2 = pd.DataFrame(JSONContent2['items'])\n",
    "print(blayney_df2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting all of the pages together into one data frame\n",
    "\n",
    "- We will use a for loop to loop through the page numbers, and add the data to a DataFrame each time.\n",
    "- First, we must create an empty DataFrame: `blayney_df_all = pd.DataFrame()`\n",
    "- We will specify a range in our for loop of range(1, 6) because we want to go from pages 1 to 5 inclusive.\n",
    "- We will add the number on as a string at the end of the URL to specify the page number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blayney_df_all = pd.DataFrame()\n",
    "\n",
    "for i in range(1,6):\n",
    "    JSONContent = requests.get(\"https://chroniclingamerica.loc.gov/search/pages/results/?andtext=castleblayney&format=json&page=\"+str(i), \n",
    "                              headers={'content-type':'application/json'}).json()\n",
    "    blayney_df_page = pd.DataFrame(JSONContent['items'])\n",
    "    blayney_df_all = pd.concat([blayney_df_all, blayney_df_page])\n",
    "\n",
    "blayney_df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 Accessing an API with authorization: YouTube\n",
    "\n",
    "https://developers.google.com/youtube/v3\n",
    "\n",
    "https://developers.google.com/youtube/v3/getting-started\n",
    "\n",
    "Create a project at the credentials page (link on this page: https://developers.google.com/youtube/registering_an_application)\n",
    "\n",
    "Click on Create Credentials and request an API key.\n",
    "\n",
    "Enable the YouTube Data API v3.\n",
    "\n",
    "Install the googleapiclient (I have commented it out to avoid installing multiple times):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade google-api-python-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary libraries\n",
    "from googleapiclient.discovery import build\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = 'YOUR_API_KEY_HERE'\n",
    "youtube = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to find the channel_ids of the channels we want to find details on.\n",
    "\n",
    "See details here on how to find channel ids: https://www.youtube.com/watch?v=qPKmPaNaCmE\n",
    "\n",
    "1. Go to the YouTube channel homepage.\n",
    "2. Right-click anywhere on the page and click 'View page source'.\n",
    "3. Use Ctrl-F to find 'channel_id=' on the page. The channel_id will appear after this text.\n",
    "4. Copy the channel_id into the Python code as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = ['UCNAf1k0yIjyGu3k9BwAg3lg',  # Sky Sports Premier League\n",
    "              'UCWw6scNyopJ0yjMu1SyOEyw',  # Talksport\n",
    "              'UCjXIw1GlwaY1IzpW_jN9iCQ',  # The Overlap\n",
    "             ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run some code to see what data we can get on the channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = youtube.channels().list(\n",
    "    part=\"snippet,contentDetails,statistics\",\n",
    "    id=','.join(channel_ids))\n",
    "response = request.execute()\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function called channel_stats to get channel statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def channel_stats(youtube, channel_ids):\n",
    "    all_data = []\n",
    "    request = youtube.channels().list(\n",
    "        part=\"snippet,contentDetails,statistics\",\n",
    "        id=','.join(channel_ids))\n",
    "    response = request.execute()\n",
    "\n",
    "    for i in range(len(response['items'])):\n",
    "        data = {\n",
    "            'channel_name': response['items'][i]['snippet']['title'],\n",
    "            'num_Subscribers': response['items'][i]['statistics']['subscriberCount'],\n",
    "            'num_views': response['items'][i]['statistics']['viewCount'],\n",
    "            'num_vids': response['items'][i]['statistics']['videoCount'],\n",
    "            'playlist_ID': response['items'][i]['contentDetails']['relatedPlaylists']['uploads']\n",
    "        }\n",
    "        all_data.append(data)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_stats(youtube, channel_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = channel_stats(youtube, channel_ids)\n",
    "channelStats = pd.DataFrame(channel)  # convert to pandas df\n",
    "channelStats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will try to get details on videos from the playlist_id from the channel 'The Overlap'. First, we extract the playlist_id from the channelStats df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_name = 'The Overlap'\n",
    "playlist_id = channelStats.loc[channelStats['channel_name'] == channel_name, 'playlist_ID'].iloc[0]\n",
    "playlist_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, create a function to extract 50 video IDs from the playlist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vid_id(youtube, playlist_id):\n",
    "    request = youtube.playlistItems().list(  # playlistItem() is gotten from the YT developer to list playlist items.\n",
    "        part=\"contentDetails\",\n",
    "        playlistId=playlist_id,\n",
    "        maxResults=50)  # to increase the results per page from the default 5 to the max 50\n",
    "    response = request.execute()\n",
    "\n",
    "    video_ids = []\n",
    "    for i in range(len(response['items'])):\n",
    "        video_ids.append(response['items'][i]['contentDetails']['videoId'])\n",
    "\n",
    "    return video_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this function on our playlist_id:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_ids = get_vid_id(youtube, playlist_id)\n",
    "video_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to get the video details from the video IDs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vid_details(youtube, video_ids):\n",
    "    combvidestats = []\n",
    "\n",
    "    for video_id in video_ids:\n",
    "        request = youtube.videos().list(\n",
    "            part='snippet,statistics',\n",
    "            id=video_id\n",
    "        )\n",
    "        response = request.execute()\n",
    "\n",
    "        for video in response['items']:\n",
    "            video_stats = {\n",
    "                'Title': video['snippet']['title'],\n",
    "                'Publish_date': video['snippet']['publishedAt'],\n",
    "                'num_views': video['statistics']['viewCount'],\n",
    "                'num_likes': video['statistics']['likeCount'],\n",
    "                'num_comm': video['statistics']['commentCount']\n",
    "            }\n",
    "            combvidestats.append(video_stats)\n",
    "\n",
    "    return combvidestats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_details = get_vid_details(youtube, video_ids)\n",
    "video_details_df = pd.DataFrame(video_details)\n",
    "video_details_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 Exercises\n",
    "\n",
    "1. Find an API online, and create a DataFrame in Python from the API data.\n",
    "2. Use the YouTube API to get details on videos from a particular YouTube channel."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}